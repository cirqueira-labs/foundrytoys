========================\nCODE SNIPPETS\n========================\nTITLE: Install Python Libraries\nDESCRIPTION: Installs the OpenAI Python SDK and the python-dotenv library using pip. python-dotenv is used for loading environment variables from a .env file.\n\nSOURCE: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/use-your-data-quickstart\n\nLANGUAGE: bash\nCODE:\n```\npip install openai\npip install python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Install Azure AI Inference Package (Python)\nDESCRIPTION: Installs the necessary Python package for interacting with Azure AI inference endpoints using pip.\n\nSOURCE: https://learn.microsoft.com/en-us/azure/ai-foundry/model-inference/how-to/configure-entra-id\n\nLANGUAGE: python\nCODE:\n```\npip install azure-ai-inference\n```\n\n----------------------------------------\n\nTITLE: Install Python Client Library\nDESCRIPTION: Installs the Azure AI Foundry Projects client library and the Azure Identity library for Python using pip.\n\nSOURCE: https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/sdk-overview\n\nLANGUAGE: shell\nCODE:\n```\npip install azure-ai-projects azure-identity\n```\n\n----------------------------------------\n\nTITLE: Create Python Project Client\nDESCRIPTION: Demonstrates creating an `AIProjectClient` instance in Python. It requires the Azure AI Foundry project endpoint and uses `DefaultAzureCredential` for authentication.\n\nSOURCE: https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/sdk-overview\n\nLANGUAGE: python\nCODE:\n```\nfrom azure.identity import DefaultAzureCredential\nfrom azure.ai.projects import AIProjectClient\n\nproject = AIProjectClient(\n  endpoint=\"your_project_endpoint\",  # Replace with your endpoint\n  credential=DefaultAzureCredential())\n\n```\n\n----------------------------------------\n\nTITLE: Python: Interact with Azure OpenAI Chat Completion Models\nDESCRIPTION: Demonstrates basic interaction with Azure OpenAI chat completion models using the Python SDK. It covers client initialization with API key and endpoint, sending a chat message, and printing the model's response content. Requires the `openai` library and environment variables for API key and endpoint.\n\nSOURCE: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/chatgpt\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom openai import AzureOpenAI\n\nclient = AzureOpenAI(\n  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n  api_version = \"2024-10-21\",\n  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n)\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\", # model = \"deployment_name\".\n    messages=[\n        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n    ]\n)\n\n#print(response)\nprint(response.model_dump_json(indent=2))\nprint(response.choices[0].message.content)\n```\n